{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmcguire81/metapy/blob/master/tutorials/4-classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3sdH0x2np3pE",
        "outputId": "bd08881e-d3bd-4be7-babf-dccda67d0eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# NOTE: this assumes you've uploaded a Python 3.7 build from our fork to Drive\n",
        "# TODO: replace this with a stock install when it's published somewhere\n",
        "%pip install /content/drive/MyDrive/metapy-0.2.13-cp37-cp37m-manylinux_2_24_x86_64.whl"
      ],
      "metadata": {
        "id": "KqEW2VmMp4qq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmAazDQApzxh"
      },
      "source": [
        "First, let's import the Python bindings, as usual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "Bs3SeVzppzyK"
      },
      "outputs": [],
      "source": [
        "import metapy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lphr95b0pzyM"
      },
      "source": [
        "Now, let's download a list of stopwords and a small dataset to begin playing around with classifiers in MeTA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a0XJSeRppzyO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget -N https://raw.githubusercontent.com/meta-toolkit/meta/master/data/lemur-stopwords.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OLkbLvkFpzyR"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget -N https://meta-toolkit.org/data/2016-01-26/ceeaus.tar.gz\n",
        "!tar xvf ceeaus.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5kv52hxpzyT"
      },
      "source": [
        "Now, let's index this dataset. Since we are doing classification experiments, we will most likely be concerning ourselves with a `ForwardIndex`, since we want to map document ids to their feature vector representations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget -N https://raw.githubusercontent.com/dmcguire81/metapy/master/tutorials/ceeaus-config.toml"
      ],
      "metadata": {
        "id": "xFFcD0kAqMyY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "N4GVKVoFpzyV"
      },
      "outputs": [],
      "source": [
        "fidx = metapy.index.make_forward_index('ceeaus-config.toml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grm7QCKkpzy7"
      },
      "source": [
        "Note that the feature set used for classification depends on your settings in the configuration file _at the time of indexing_. If you want to play with different feature sets, remember to change your `analyzer` pipeline in the configuration file, and also to **reindex** your documents!\n",
        "\n",
        "Here, we've just chosen simple unigram words. This is actually a surprisingly good baseline feature set for many text classification problems.\n",
        "\n",
        "Now that we have a `ForwardIndex` on disk, we need to load the documents we want to start playing with into memory. Since this is a small enough dataset, let's load the whole thing into memory at once.\n",
        "\n",
        "We need to decide what kind of dataset we're using. MeTA has classes for binary classification (`BinaryDataset`) and multi-class classification (`MulticlassDataset`), which you should choose from depending on the kind of classification problem you're dealing with. Let's see how many labels we have in our corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7iUqraWVpzy-",
        "outputId": "93c79ed3-9da9-4a3a-bfa9-10063338a1f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "fidx.num_labels()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjH_ETiSpzzC"
      },
      "source": [
        "Since this is more than 2, we likely want a `MulticlassDataset` so we can learn a classifier that can predict which of these three labels a document should have. (But we might be interested in only determining one particular class from the rest, in which case we might actually want a `BinaryDataset`.)\n",
        "\n",
        "For now, let's focus on the multi-class case, as that likely makes the most sense for this kind of data. Let's load or documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SGN2Mp9apzzE",
        "outputId": "f6b5ea13-ea40-4014-afee-0b9b614a9c36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1008"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dset = metapy.classify.MulticlassDataset(fidx)\n",
        "len(dset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilb_7ChBpzzG"
      },
      "source": [
        "We have 1008 documents, split across three labels. What are our labels?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YC7WT--Vpzzt",
        "outputId": "5efab172-c8eb-4daa-c9d5-5137b6a4cbe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chinese', 'english', 'japanese'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "set([dset.label(instance) for instance in dset])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF48y29apzzw"
      },
      "source": [
        "This dataset is a small collection of essays written by a bunch of students with different first languages. Our goal will be to try to identify whether an essay was written by a native-Chinese speaker, a native-English speaker, or a native-Japanese speaker.\n",
        "\n",
        "Now, because these in-memory datasets can potentially be quite large, it's beneficial to not make unnecessary copies of them to, for example, create a new list that's shuffled that contains the same documents. In most cases, you'll be operating with a `DatasetView` (either `MulticlassDatasetView` or `BinaryDatasetView`) so that you can do things like shuffle or rotate the contents of a dataset without having to actually modify it. Doing so is pretty easy: you can use Python's slicing API, or you can just construct one directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "gB8F8hsBpzzz"
      },
      "outputs": [],
      "source": [
        "view = dset[0:len(dset)+1]\n",
        "# or\n",
        "view = metapy.classify.MulticlassDatasetView(dset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnAMOFbcpzz0"
      },
      "source": [
        "Now we can, for example, shuffle this view without changing the underlying datsaet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "61nGhyyepzz1",
        "outputId": "5ddb7447-ebcc-4c5f-d706-1650418ec11b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 vs 0\n"
          ]
        }
      ],
      "source": [
        "view.shuffle()\n",
        "print(\"{} vs {}\".format(view[0].id, dset[0].id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAgW6iGqpzz5"
      },
      "source": [
        "The view has been shuffled and now has documents in random order (useful in many cases to make sure that you don't have clumps of the same-labeled documents together, or to just permute the documents in a stochastic learning algorithm), but the underlying dataset is still sorted by id.\n",
        "\n",
        "We can also use this slicing API to create a random training and testing set from our shuffled views (views also support slicing). Let's make a 75-25 split of training-testing data. (Note that's really important that we already shuffled the view!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "jOWtasqRpzz5"
      },
      "outputs": [],
      "source": [
        "training = view[0:int(0.75*len(view))]\n",
        "testing = view[int(0.75*len(view)):len(view)+1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWgBR17mpz0f"
      },
      "source": [
        "Now, we're ready to train a classifier! Let's start with very simple one: [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier).\n",
        "\n",
        "In MeTA, construction of a classifier implies training of that model. Let's train a Naive Bayes classifier on our training view now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "gsTbSR7ppz0g"
      },
      "outputs": [],
      "source": [
        "nb = metapy.classify.NaiveBayes(training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkYywbrtpz0g"
      },
      "source": [
        "We can now classify individual documents like so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dSTmKbDPpz0h",
        "outputId": "b64a3d64-752c-47dd-e3bc-08ed1b0361b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'japanese'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "nb.classify(testing[0].weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUGqbVSapz0i"
      },
      "source": [
        "We might be more interested in how well we classify the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "a6YF4zV0pz0l",
        "outputId": "a1ea19d2-f545-41c5-81ee-85866f6fad69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            chinese   english   japanese  \n",
            "          ------------------------------\n",
            "  chinese | \u001b[1m0.833\u001b[22m     0.0417    0.125     \n",
            "  english | 0.025     \u001b[1m0.9\u001b[22m       0.075     \n",
            " japanese | 0.0213    0.0106    \u001b[1m0.968\u001b[22m     \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mtrx = nb.test(testing)\n",
        "print(mtrx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx1ic1gspz0m"
      },
      "source": [
        "The `test()` method of MeTA's classifiers returns to you a `ConfusionMatrix`, which contains useful information about what kinds of mistakes your classifier is making.\n",
        "\n",
        "(Note that, due to the random shuffling, you might see different results than we do here.)\n",
        "\n",
        "For example, we can see that this classifier seems to have some trouble with confusing native-Chinese students' essays with those of native-Japanese students. We can tell that by looking at the rows of the confusion matrix. Each row tells you what fraction of documents with that _true_ label were assigned the label for each column by the classifier. In the case of the native-Chinese label, we can see that 25% of the time they were miscategorized as being native-Japanese.\n",
        "\n",
        "The `ConfusionMatrix` also computes a lot of metrics that are commonly used in classifier evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MoRkUliLpz0o",
        "outputId": "5df4e565-ba3b-459b-d242-823c277f1b86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "\u001b[1mClass\u001b[22m       \u001b[1mF1 Score\u001b[22m    \u001b[1mPrecision\u001b[22m   \u001b[1mRecall\u001b[22m      \u001b[1mClass Dist\u001b[22m  \n",
            "------------------------------------------------------------\n",
            "chinese     0.816       0.8         0.833       0.0952      \n",
            "english     0.911       0.923       0.9         0.159       \n",
            "japanese    0.968       0.968       0.968       0.746       \n",
            "------------------------------------------------------------\n",
            "\u001b[1mTotal\u001b[22m       \u001b[1m0.945\u001b[22m       \u001b[1m0.945\u001b[22m       \u001b[1m0.944\u001b[22m       \n",
            "------------------------------------------------------------\n",
            "252 predictions attempted, overall accuracy: 0.944\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mtrx.print_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00To3Ptbpz0p"
      },
      "source": [
        "If we want to make sure that the classifier isn't overfitting to our training data, a common approach is to do [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)). Let's run CV for our Naive Bayes classifier across the whole dataset, using 5-folds, to get an idea of how well we might generalize to new data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "Ba1gIuefpz0p"
      },
      "outputs": [],
      "source": [
        "mtrx = metapy.classify.cross_validate(lambda fold: metapy.classify.NaiveBayes(fold), view, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at3nFkNspz0p"
      },
      "source": [
        "`cross_validate()` returns a `ConfusionMatrix` just like `test()` does. We give it a function to use to create the trained classifiers for each fold, and then pass in the dataset view containing all of our documents, and the number of folds we want to use.\n",
        "\n",
        "Let's see how we did."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9Joye8Nipz0p",
        "outputId": "ea5a6931-66f3-4811-e855-613bf0227189",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            chinese   english   japanese  \n",
            "          ------------------------------\n",
            "  chinese | \u001b[1m0.87\u001b[22m      0.0217    0.109     \n",
            "  english | 0.0208    \u001b[1m0.917\u001b[22m     0.0625    \n",
            " japanese | 0.0169    0.0104    \u001b[1m0.973\u001b[22m     \n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "\u001b[1mClass\u001b[22m       \u001b[1mF1 Score\u001b[22m    \u001b[1mPrecision\u001b[22m   \u001b[1mRecall\u001b[22m      \u001b[1mClass Dist\u001b[22m  \n",
            "------------------------------------------------------------\n",
            "chinese     0.851       0.833       0.87        0.0915      \n",
            "english     0.923       0.93        0.917       0.143       \n",
            "japanese    0.974       0.975       0.973       0.765       \n",
            "------------------------------------------------------------\n",
            "\u001b[1mTotal\u001b[22m       \u001b[1m0.955\u001b[22m       \u001b[1m0.956\u001b[22m       \u001b[1m0.955\u001b[22m       \n",
            "------------------------------------------------------------\n",
            "1005 predictions attempted, overall accuracy: 0.955\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(mtrx)\n",
        "mtrx.print_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9SX0wACpz0r"
      },
      "source": [
        "Now let's do the same thing, but for an arguably stronger baseline: [SVM](https://en.wikipedia.org/wiki/Support_vector_machine).\n",
        "\n",
        "MeTA's implementation of SVM is actually an approximation using [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) on the [hinge loss](https://en.wikipedia.org/wiki/Hinge_loss). It's implemented as a `BinaryClassifier`, so we will need to adapt it before it can be used to solve our multi-class clasification problem.\n",
        "\n",
        "MeTA provides two different adapters for this scenario: [One-vs-All](https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest) and [One-vs-One](https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "id": "tud5wyWIpz1R"
      },
      "outputs": [],
      "source": [
        "ova = metapy.classify.OneVsAll(training, metapy.classify.SGD, loss_id='hinge')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-9_owdBpz1U"
      },
      "source": [
        "We construct the `OneVsAll` reduction by providing it the training documents, the name of a binary classifier, and then (as keyword arguments) any additional arguments to that chosen classifier. In this case, we use `loss_id` to specify the loss function to use.\n",
        "\n",
        "We can now use `OneVsAll` just like any other classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1zvUSkr_pz1X",
        "outputId": "9b1cdd85-3fc8-47ed-8eed-3e7c122c8198",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            chinese   english   japanese  \n",
            "          ------------------------------\n",
            "  chinese | \u001b[1m0.792\u001b[22m     -         0.208     \n",
            "  english | -         \u001b[1m0.9\u001b[22m       0.1       \n",
            " japanese | 0.00532   0.00532   \u001b[1m0.989\u001b[22m     \n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "\u001b[1mClass\u001b[22m       \u001b[1mF1 Score\u001b[22m    \u001b[1mPrecision\u001b[22m   \u001b[1mRecall\u001b[22m      \u001b[1mClass Dist\u001b[22m  \n",
            "------------------------------------------------------------\n",
            "chinese     0.864       0.95        0.792       0.0952      \n",
            "english     0.935       0.973       0.9         0.159       \n",
            "japanese    0.971       0.954       0.989       0.746       \n",
            "------------------------------------------------------------\n",
            "\u001b[1mTotal\u001b[22m       \u001b[1m0.956\u001b[22m       \u001b[1m0.957\u001b[22m       \u001b[1m0.956\u001b[22m       \n",
            "------------------------------------------------------------\n",
            "252 predictions attempted, overall accuracy: 0.956\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mtrx = ova.test(testing)\n",
        "print(mtrx)\n",
        "mtrx.print_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Vi5zd-sopz1Z",
        "outputId": "9f76a631-8907-47bc-c3db-d81d120c9452",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            chinese   english   japanese  \n",
            "          ------------------------------\n",
            "  chinese | \u001b[1m0.772\u001b[22m     0.0326    0.196     \n",
            "  english | -         \u001b[1m0.903\u001b[22m     0.0972    \n",
            " japanese | 0.0026    0.0065    \u001b[1m0.991\u001b[22m     \n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "\u001b[1mClass\u001b[22m       \u001b[1mF1 Score\u001b[22m    \u001b[1mPrecision\u001b[22m   \u001b[1mRecall\u001b[22m      \u001b[1mClass Dist\u001b[22m  \n",
            "------------------------------------------------------------\n",
            "chinese     0.861       0.973       0.772       0.0915      \n",
            "english     0.922       0.942       0.903       0.143       \n",
            "japanese    0.975       0.96        0.991       0.765       \n",
            "------------------------------------------------------------\n",
            "\u001b[1mTotal\u001b[22m       \u001b[1m0.958\u001b[22m       \u001b[1m0.958\u001b[22m       \u001b[1m0.958\u001b[22m       \n",
            "------------------------------------------------------------\n",
            "1005 predictions attempted, overall accuracy: 0.958\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mtrx = metapy.classify.cross_validate(lambda fold: metapy.classify.OneVsAll(fold, metapy.classify.SGD, loss_id='hinge'), view, 5)\n",
        "print(mtrx)\n",
        "mtrx.print_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVHeiZbDpz1Z"
      },
      "source": [
        "That should be enough to get you started! Try looking at `help(metapy.classify)` for a list of what's included in the bindings."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.10 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "1b32ce2ef2cf43bd49542c1d6f40df2390cf5e4ba090c99d923ccca864eaed4d"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
